{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 감정사전을 이용한 감정 분석\n",
    "- 화장품 특성 단어 --> 수작업으로 사전 구축\n",
    "- 감정사전을 활용한 리뷰 레이블 태깅\n",
    "- Modeling\n",
    "    - 나이브 베이즈 모형\n",
    "    - doc2vec\n",
    "        - 모델 평가: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Twitter\n",
    "from time import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 화장품 특성 단어 --> 수작업으로 감정 단어 사전 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 단어 사전 로드\n",
    "def read_data_comma(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.split(', ') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_dic = read_data_comma('data/cosmetic_words_labled.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['좋다/Adjective', '1'],\n",
       " ['있다/Adjective', '1'],\n",
       " ['같다/Adjective', '1'],\n",
       " ['바르다/Verb', '1'],\n",
       " ['향/Noun', '1'],\n",
       " ['않다/Verb', '0'],\n",
       " ['없다/Adjective', '0'],\n",
       " ['자다/Verb', '1'],\n",
       " ['너무/Noun', '0'],\n",
       " ['때/Noun', '0']]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dic[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dic[0][0] == '대비/Noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_neg_dic(words_dic):\n",
    "    pos_dic = []\n",
    "    neg_dic = []\n",
    "    for word in words_dic:\n",
    "        if word[1] == '1':\n",
    "            pos_dic.append(word)\n",
    "        else:\n",
    "            neg_dic.append(word)\n",
    "    return pos_dic, neg_dic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dic, neg_dic = pos_neg_dic(words_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 253)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_dic), len(neg_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('좋다/Adjective', '않다/Verb')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dic[0][0], neg_dic[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dic = [word[0] for word in pos_dic]\n",
    "neg_dic = [word[0] for word in neg_dic]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_docs = load_pickle('data/review_docs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21222"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['꾸다/Verb',\n",
       " '덕이/Noun',\n",
       " '거나/Noun',\n",
       " '끈/Noun',\n",
       " '적임/Noun',\n",
       " '이/Josa',\n",
       " '없다/Adjective',\n",
       " '좋다/Adjective',\n",
       " '템/Noun',\n",
       " '이지만/Josa',\n",
       " '바다/Noun',\n",
       " '가다/Verb',\n",
       " '팔다리/Noun',\n",
       " '에/Josa',\n",
       " '몇번/Noun',\n",
       " '바르다/Verb',\n",
       " '나니/Noun',\n",
       " '사라지다/Verb',\n",
       " '버리다/Verb',\n",
       " '양은/Noun',\n",
       " '적어도/Adverb',\n",
       " '재다/Verb',\n",
       " '매다/Verb',\n",
       " '할꾸얌/Noun']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_docs[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감정사전을 활용한 리뷰 레이블 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_list = []\n",
    "for review in review_docs:\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for word in review:\n",
    "        if word in pos_dic:\n",
    "            pos += 1\n",
    "        elif word in neg_dic:\n",
    "            neg += 1\n",
    "            \n",
    "    if (pos - neg) == 0:\n",
    "        pol = 0\n",
    "    else:\n",
    "        pol = (pos - neg)/(pos + neg)\n",
    "    polarity_list.append(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21222"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_n = 0\n",
    "neg_n = 0\n",
    "sentiment = []\n",
    "for pol in polarity_list:\n",
    "    if pol > 0:\n",
    "        pos_n += 1\n",
    "        sentiment.append(1)\n",
    "    else:\n",
    "        neg_n += 1\n",
    "        sentiment.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13079, 8143, 2360)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_n, neg_n, (pos_n+neg_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1.0,\n",
       " -0.5384615384615384,\n",
       " 0.42857142857142855,\n",
       " -0.5,\n",
       " -0.09090909090909091,\n",
       " 0.8461538461538461,\n",
       " 0.14285714285714285,\n",
       " 0.2727272727272727,\n",
       " 0.5]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmetic = pd.read_csv('data/cosmetics_reviews_final.csv')\n",
    "reviews = cosmetic['review']\n",
    "review_labled = pd.DataFrame(columns=['review', 'sentiment'])\n",
    "review_labled['review'] = reviews\n",
    "review_labled['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>트리플어피치 쓰는데 음    발색도 별로 텍스쳐가 정말 뭐라하지 너무 기름진데 촉촉...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>치크로만 쓰는데 굉장히 여리여리라게 발색됨</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>색은 둘째치고 틴트가 지속력이 없음  올려도 지워지니 살 필요가 없다  립브러쉬 쓰...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>루즈G 립스틱이랑 세트인 컴팩트   일단 컴팩트 디자인이 엄청 다양해요  심플한 검...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164 쓰는데 고급진 핑크에요   발림성이 너무 맘에 들었어요 지속은 좀 아쉬웠고 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>원래 립스틱타입 쓰다가 매장언니 추천으로 샀는데 이가격에도 쓰게되는 애증의 아이템임...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여름이라 팔꿈치랑 복숭아뼈 같은부위는 되게 자주 스크럽하는 편인데 꽤 깨끗하게 잘 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>케이스 이뻐서 샀는데 너무 촉촉함 지속력이 너무 없다    그래도 꿋꿋이 발랐었어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>상큼한 레몬향 촉촉하고 산뜻하게 보습이 돼요 겨울에는 좀 부족할 듯 다른 립밤들보다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>케이스 귀엽  향은 진짜 좋음  이것만 바르면 목이 따갑고 먼지 먹은 느낌 정말 싫음</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>찐득   찐득</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>저한텐많이 매트하진않았지만 발색이 거의나질않네요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>시트가 검정색이라그런지 팩 할 때 그 얼굴에 밀착 안돼서 뜨는게 덜 보여요  그래서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>얘는 단종 되었지만 학생틴트로 추천해요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>향은 호불호가 갈리지만 저에게는 좋았어요  향기가 오래 지속되었으면 좋겠다고 생각했...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>557호랑 765호를 섞어서 쓰는데 이뻐요    물론 40000원이라 비싸긴 하지만...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>비싼 가격에 성분 안좋은걸 사서 먹었구나요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>구매한 색상  17호 파티레드 지속력은 좋은데 딱히 이 돈내고 사기엔 아닌 것같네요...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>겉돌고 각질 부각이 되요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>전 초록이 써보고 화이트도 좋을지 알고 써봤는데 트러블 올라오더라고요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "0   트리플어피치 쓰는데 음    발색도 별로 텍스쳐가 정말 뭐라하지 너무 기름진데 촉촉...          0\n",
       "1                             치크로만 쓰는데 굉장히 여리여리라게 발색됨          1\n",
       "2   색은 둘째치고 틴트가 지속력이 없음  올려도 지워지니 살 필요가 없다  립브러쉬 쓰...          0\n",
       "3   루즈G 립스틱이랑 세트인 컴팩트   일단 컴팩트 디자인이 엄청 다양해요  심플한 검...          1\n",
       "4   164 쓰는데 고급진 핑크에요   발림성이 너무 맘에 들었어요 지속은 좀 아쉬웠고 ...          0\n",
       "5   원래 립스틱타입 쓰다가 매장언니 추천으로 샀는데 이가격에도 쓰게되는 애증의 아이템임...          0\n",
       "6   여름이라 팔꿈치랑 복숭아뼈 같은부위는 되게 자주 스크럽하는 편인데 꽤 깨끗하게 잘 ...          1\n",
       "7      케이스 이뻐서 샀는데 너무 촉촉함 지속력이 너무 없다    그래도 꿋꿋이 발랐었어요          1\n",
       "8   상큼한 레몬향 촉촉하고 산뜻하게 보습이 돼요 겨울에는 좀 부족할 듯 다른 립밤들보다...          1\n",
       "9     케이스 귀엽  향은 진짜 좋음  이것만 바르면 목이 따갑고 먼지 먹은 느낌 정말 싫음          1\n",
       "10                                            찐득   찐득          0\n",
       "11                         저한텐많이 매트하진않았지만 발색이 거의나질않네요          0\n",
       "12  시트가 검정색이라그런지 팩 할 때 그 얼굴에 밀착 안돼서 뜨는게 덜 보여요  그래서...          1\n",
       "13                              얘는 단종 되었지만 학생틴트로 추천해요          0\n",
       "14  향은 호불호가 갈리지만 저에게는 좋았어요  향기가 오래 지속되었으면 좋겠다고 생각했...          1\n",
       "15  557호랑 765호를 섞어서 쓰는데 이뻐요    물론 40000원이라 비싸긴 하지만...          0\n",
       "16                            비싼 가격에 성분 안좋은걸 사서 먹었구나요          0\n",
       "17  구매한 색상  17호 파티레드 지속력은 좋은데 딱히 이 돈내고 사기엔 아닌 것같네요...          1\n",
       "18                                      겉돌고 각질 부각이 되요          0\n",
       "19             전 초록이 써보고 화이트도 좋을지 알고 써봤는데 트러블 올라오더라고요          0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_labled.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_labled.to_csv('data/review_labled.txt', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "with codecs.open(\"data/review_labled.txt\", encoding='utf-8') as f:\n",
    "    data = [line.split(',') for line in f.read().splitlines()]\n",
    "    data = data[1:]   # header 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['치크로만 쓰는데 굉장히 여리여리라게 발색됨', '1']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(*data))[0]\n",
    "y = np.array(list(zip(*data))[1], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습용 데이터와 테스트용 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state = 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자극 장난아님 겁나 뜨거움 그리고 때처럼 밀어내는거라 민감성은 안쓰는게 좋다고 봄  바디용으로 쓰다가 그것도 성질나서 버림',\n",
       " '저는 친구한테 추천받아서 샀어요  일단 매트한 질감이 아니라 몰랑몰랑 굳은 연고 같아요 그래서 발림성은 최고   일단  애교살에  발라주기 짱인거 같아요 부담스러운 굵은 입자에 반짝이가 아니라서 눈밑에 바르면 은은하게 반짝거려요   또 섀도우로는 기본 눈 메이컵 다  하고  눈두덩이 중간부분에 포인트로 펄감을 주기위해  살짝 올리는것도 이쁘더라구요  또 양이 많아서   오랜기간동안 써도 안줄어요     아참  붓으로 바르는것보단 손으로 바르는게 훨씬 좋아요   음 아쉬운건 조금  뭉침이 있다는거',\n",
       " '루나솔 발색도 좋고 지속성도 좋아요  여러색을 한번에 사용할수있는 장점이 있어요  디올쓰다가 바꿨어요  펄 입자도 크지않고 은은해서 평소 사용하기좋고 색상도 자주사용하는 색으로 모아놔서 굿굿 저는 이것만 써요',\n",
       " '처음 쓸 때에는 향이 너무 이상해서 코를 막고 썼는데 쓰다 보니 익숙해진다  오히려 좋은 것 같기도 하고  보습이 잘 되면서 흡수가 빨라 끈적이지 않는다  내가 싫어하는 물감 용기에 물감 뚜껑인 게 아쉽다',\n",
       " '약간의 끈적임이 있는 콧물 형태지만 얼굴에 바르고 톡톡 두드려주다보면 금방 스며들어요 엄마에게 선물해드렸는데 좋아하셨어요',\n",
       " '별로    드라마틱한 효과 전혀없음 그래도 5일인데',\n",
       " '유분이 많아서 저한테는 좀 별로였던거 같아요',\n",
       " '샴페인 색상 쓰는데 언더에 바르기 좋음 반짝반짝',\n",
       " '마른머리에 웨이브 1도 안잡아줘서 조금 젖은 머리에 하니까 웨이브 약간 잡혀용',\n",
       " '하이류']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 모형\n",
    "##### - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model1 = Pipeline([\n",
    "            ('vect', CountVectorizer()), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 793 ms, sys: 36 ms, total: 829 ms\n",
      "Wall time: 834 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('mb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.54      0.66      1619\n",
      "          1       0.77      0.95      0.85      2626\n",
      "\n",
      "avg / total       0.80      0.79      0.78      4245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - TF-IDF 방법 사용 : TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "model2 = Pipeline([\n",
    "            ('vect', TfidfVectorizer()), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 807 ms, sys: 30.2 ms, total: 837 ms\n",
      "Wall time: 839 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...True,\n",
       "        vocabulary=None)), ('mb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.23      0.37      1619\n",
      "          1       0.68      1.00      0.81      2626\n",
      "\n",
      "avg / total       0.79      0.70      0.64      4245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Twitter 형태소 분석기 사용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize_pos)), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 979 ms, total: 1min 6s\n",
      "Wall time: 57.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize_pos at 0x130338bf8>, vocabulary=None)), ('mb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.72      0.76      1619\n",
      "          1       0.84      0.90      0.87      2626\n",
      "\n",
      "avg / total       0.83      0.83      0.83      4245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Pipeline([\n",
    "            ('vect', TfidfVectorizer(tokenizer=tokenize_pos)), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.6 s, sys: 556 ms, total: 55.1 s\n",
      "Wall time: 55.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...True,\n",
       "        vocabulary=None)), ('mb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.27      0.42      1619\n",
      "          1       0.69      0.99      0.81      2626\n",
      "\n",
      "avg / total       0.79      0.72      0.66      4245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - (1,2)-gram 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Pipeline([\n",
    "            ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 s, sys: 490 ms, total: 53.5 s\n",
      "Wall time: 53.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...True,\n",
       "        vocabulary=None)), ('mb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.21      1619\n",
      "          1       0.65      1.00      0.79      2626\n",
      "\n",
      "avg / total       0.78      0.66      0.57      4245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.6 s, sys: 521 ms, total: 55.2 s\n",
      "Wall time: 55.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize_pos at 0x130338bf8>, vocabulary=None)), ('mb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.60      0.73      1619\n",
      "          1       0.80      0.97      0.88      2626\n",
      "\n",
      "avg / total       0.85      0.83      0.82      4245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model6.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> model6 (CountVectorizer, 형태소분석, (1,2)-gram 사용)의 성능이 가장 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.25, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15916\n",
      "5306\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))      # nrows: 150000\n",
    "print(len(test_set))       # nrows: 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = [(tokenize(row[0]), row[1]) for row in train_set]\n",
    "test_docs = [(tokenize(row[0]), row[1]) for row in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15916, 5306)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_docs), len(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_train_docs = [TaggedDocument(d, [c]) for d, c in train_docs]\n",
    "tagged_test_docs = [TaggedDocument(d, [c]) for d, c in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 병렬 연산 처리\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그값 출력\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:28:16,793 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "/usr/local/lib/python3.6/site-packages/gensim/models/doc2vec.py:535: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# 토큰 벡터화(word embedding) 하기\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "doc_vectorizer = doc2vec.Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=8,        # distance between the predicted word and context words\n",
    "    size=300,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=20,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=cores,   # multi cpu\n",
    "    hs = 1,          # hierarchical softmax / default 0\n",
    "    negative = 10,   # negative sampling / default 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:32:24,389 : INFO : collecting all words and their counts\n",
      "2018-08-01 13:32:24,391 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-08-01 13:32:24,637 : INFO : PROGRESS: at example #10000, processed 393403 words (1603857/s), 12912 word types, 2 tags\n",
      "2018-08-01 13:32:24,739 : INFO : collected 15708 word types and 2 unique tags from a corpus of 15916 examples and 632490 words\n",
      "2018-08-01 13:32:24,740 : INFO : Loading a fresh vocabulary\n",
      "2018-08-01 13:32:24,986 : INFO : effective_min_count=20 retains 2462 unique words (15% of original 15708, drops 13246)\n",
      "2018-08-01 13:32:24,987 : INFO : effective_min_count=20 leaves 587746 word corpus (92% of original 632490, drops 44744)\n",
      "2018-08-01 13:32:24,997 : INFO : deleting the raw counts dictionary of 15708 items\n",
      "2018-08-01 13:32:24,999 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2018-08-01 13:32:24,999 : INFO : downsampling leaves estimated 470187 word corpus (80.0% of prior 587746)\n",
      "2018-08-01 13:32:25,004 : INFO : constructing a huffman tree from 2462 words\n",
      "2018-08-01 13:32:25,119 : INFO : built huffman tree with maximum node depth 15\n",
      "2018-08-01 13:32:25,138 : INFO : estimated required memory for 2462 words and 300 dimensions: 10589400 bytes\n",
      "2018-08-01 13:32:25,139 : INFO : resetting layer weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4)'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 로드\n",
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "str(doc_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15916, 5)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터화를 하기 위한 파라미터 확인\n",
    "doc_vectorizer.corpus_count, doc_vectorizer.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  after removing the cwd from sys.path.\n",
      "2018-08-01 13:36:14,828 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:36:16,168 : INFO : EPOCH 1 - PROGRESS: at 8.06% examples, 28769 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:17,280 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 40818 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:18,530 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 43663 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:19,922 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 43742 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:21,051 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 45695 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:22,204 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 46832 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:23,346 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 47738 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:24,514 : INFO : EPOCH 1 - PROGRESS: at 96.12% examples, 48301 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:36:24,515 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:36:24,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:36:24,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:36:24,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:36:24,571 : INFO : EPOCH - 1 : training on 632490 raw words (486560 effective words) took 9.7s, 49980 effective words/s\n",
      "2018-08-01 13:36:25,755 : INFO : EPOCH 2 - PROGRESS: at 8.06% examples, 32607 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:26,996 : INFO : EPOCH 2 - PROGRESS: at 20.65% examples, 41318 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:28,205 : INFO : EPOCH 2 - PROGRESS: at 33.46% examples, 44494 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:29,439 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 45799 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:30,661 : INFO : EPOCH 2 - PROGRESS: at 58.87% examples, 46698 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:31,725 : INFO : EPOCH 2 - PROGRESS: at 69.89% examples, 47228 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:33,030 : INFO : EPOCH 2 - PROGRESS: at 77.40% examples, 44441 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:34,033 : INFO : EPOCH 2 - PROGRESS: at 85.03% examples, 43764 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:35,263 : INFO : EPOCH 2 - PROGRESS: at 89.59% examples, 40866 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:35,923 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:36:35,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:36:36,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:36:36,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:36:36,075 : INFO : EPOCH - 2 : training on 632490 raw words (485949 effective words) took 11.5s, 42292 effective words/s\n",
      "2018-08-01 13:36:37,457 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 27795 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:39,071 : INFO : EPOCH 3 - PROGRESS: at 20.61% examples, 33390 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:40,095 : INFO : EPOCH 3 - PROGRESS: at 31.82% examples, 38256 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:41,814 : INFO : EPOCH 3 - PROGRESS: at 39.71% examples, 33455 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:43,311 : INFO : EPOCH 3 - PROGRESS: at 52.26% examples, 35002 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:44,336 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 34382 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:45,377 : INFO : EPOCH 3 - PROGRESS: at 66.70% examples, 34647 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:46,593 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 32820 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:48,130 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 33718 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:49,268 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 35151 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:36:49,269 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:36:49,410 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:36:49,424 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:36:49,495 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:36:49,496 : INFO : EPOCH - 3 : training on 632490 raw words (486317 effective words) took 13.4s, 36255 effective words/s\n",
      "2018-08-01 13:36:50,736 : INFO : EPOCH 4 - PROGRESS: at 7.92% examples, 31029 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:51,979 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 40299 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:53,272 : INFO : EPOCH 4 - PROGRESS: at 33.35% examples, 42769 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:54,493 : INFO : EPOCH 4 - PROGRESS: at 46.07% examples, 44582 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:55,734 : INFO : EPOCH 4 - PROGRESS: at 58.84% examples, 45533 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:36:56,948 : INFO : EPOCH 4 - PROGRESS: at 71.41% examples, 46342 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:58,159 : INFO : EPOCH 4 - PROGRESS: at 83.56% examples, 46922 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:36:59,381 : INFO : EPOCH 4 - PROGRESS: at 95.33% examples, 46907 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:36:59,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:36:59,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:36:59,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:36:59,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:36:59,441 : INFO : EPOCH - 4 : training on 632490 raw words (486056 effective words) took 9.9s, 48919 effective words/s\n",
      "2018-08-01 13:37:00,647 : INFO : EPOCH 5 - PROGRESS: at 7.92% examples, 31814 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:02,090 : INFO : EPOCH 5 - PROGRESS: at 20.65% examples, 37740 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:03,497 : INFO : EPOCH 5 - PROGRESS: at 33.35% examples, 39789 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:04,747 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 41954 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:05,972 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 43478 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:07,311 : INFO : EPOCH 5 - PROGRESS: at 71.41% examples, 43845 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:08,565 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 44511 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:09,925 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 44179 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:37:09,927 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:37:10,054 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:37:10,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:37:10,111 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:37:10,112 : INFO : EPOCH - 5 : training on 632490 raw words (485656 effective words) took 10.7s, 45540 effective words/s\n",
      "2018-08-01 13:37:10,113 : INFO : training on a 3162450 raw words (2430538 effective words) took 55.3s, 43966 effective words/s\n",
      "2018-08-01 13:37:10,114 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:37:11,376 : INFO : EPOCH 1 - PROGRESS: at 8.00% examples, 30703 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:12,988 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 34881 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:14,047 : INFO : EPOCH 1 - PROGRESS: at 28.47% examples, 35229 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:37:15,242 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 31515 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:16,322 : INFO : EPOCH 1 - PROGRESS: at 39.74% examples, 30977 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:17,482 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 30260 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:18,490 : INFO : EPOCH 1 - PROGRESS: at 55.57% examples, 32085 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:19,797 : INFO : EPOCH 1 - PROGRESS: at 65.34% examples, 32510 words/s, in_qsize 8, out_qsize 1\n",
      "2018-08-01 13:37:21,083 : INFO : EPOCH 1 - PROGRESS: at 77.53% examples, 34266 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:22,319 : INFO : EPOCH 1 - PROGRESS: at 89.59% examples, 35780 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:22,717 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:37:22,946 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:37:22,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:37:23,023 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:37:23,025 : INFO : EPOCH - 1 : training on 632490 raw words (485733 effective words) took 12.9s, 37669 effective words/s\n",
      "2018-08-01 13:37:24,303 : INFO : EPOCH 2 - PROGRESS: at 8.00% examples, 30281 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:25,551 : INFO : EPOCH 2 - PROGRESS: at 20.65% examples, 39706 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:26,868 : INFO : EPOCH 2 - PROGRESS: at 33.35% examples, 42065 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:27,921 : INFO : EPOCH 2 - PROGRESS: at 42.96% examples, 42400 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:29,143 : INFO : EPOCH 2 - PROGRESS: at 52.26% examples, 41410 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:30,474 : INFO : EPOCH 2 - PROGRESS: at 65.34% examples, 42239 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:31,716 : INFO : EPOCH 2 - PROGRESS: at 77.40% examples, 43240 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:33,099 : INFO : EPOCH 2 - PROGRESS: at 89.72% examples, 43359 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:33,621 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:37:33,747 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:37:33,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:37:33,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:37:33,870 : INFO : EPOCH - 2 : training on 632490 raw words (485880 effective words) took 10.8s, 44861 effective words/s\n",
      "2018-08-01 13:37:35,093 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 31622 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:36,358 : INFO : EPOCH 3 - PROGRESS: at 20.65% examples, 40310 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:37,667 : INFO : EPOCH 3 - PROGRESS: at 33.35% examples, 42594 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:38,990 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 43549 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:40,308 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 44169 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:41,623 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 44556 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:42,935 : INFO : EPOCH 3 - PROGRESS: at 83.60% examples, 44838 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:44,011 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 45725 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:37:44,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:37:44,228 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:37:44,287 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:37:44,322 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:37:44,323 : INFO : EPOCH - 3 : training on 632490 raw words (486211 effective words) took 10.4s, 46552 effective words/s\n",
      "2018-08-01 13:37:45,655 : INFO : EPOCH 4 - PROGRESS: at 7.92% examples, 28973 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:46,995 : INFO : EPOCH 4 - PROGRESS: at 20.61% examples, 37525 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:48,288 : INFO : EPOCH 4 - PROGRESS: at 33.35% examples, 40787 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:49,785 : INFO : EPOCH 4 - PROGRESS: at 45.97% examples, 40803 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:51,146 : INFO : EPOCH 4 - PROGRESS: at 58.87% examples, 41661 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:52,164 : INFO : EPOCH 4 - PROGRESS: at 69.89% examples, 43087 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:53,311 : INFO : EPOCH 4 - PROGRESS: at 77.53% examples, 41826 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:54,670 : INFO : EPOCH 4 - PROGRESS: at 89.59% examples, 42228 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:55,363 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:37:55,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:37:55,442 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:37:55,563 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:37:55,564 : INFO : EPOCH - 4 : training on 632490 raw words (486063 effective words) took 11.2s, 43278 effective words/s\n",
      "2018-08-01 13:37:56,964 : INFO : EPOCH 5 - PROGRESS: at 8.00% examples, 27542 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:37:58,262 : INFO : EPOCH 5 - PROGRESS: at 20.65% examples, 37104 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:37:59,608 : INFO : EPOCH 5 - PROGRESS: at 33.41% examples, 39935 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:00,883 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 41900 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:02,217 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 42728 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:03,510 : INFO : EPOCH 5 - PROGRESS: at 71.41% examples, 43466 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:04,843 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 43821 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:05,923 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 44776 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:38:05,925 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:38:06,137 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:38:06,167 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:38:06,251 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:38:06,252 : INFO : EPOCH - 5 : training on 632490 raw words (486291 effective words) took 10.7s, 45535 effective words/s\n",
      "2018-08-01 13:38:06,255 : INFO : training on a 3162450 raw words (2430178 effective words) took 56.1s, 43289 effective words/s\n",
      "2018-08-01 13:38:06,259 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:38:07,564 : INFO : EPOCH 1 - PROGRESS: at 8.00% examples, 29634 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:08,827 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 39030 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:10,179 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 41229 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:11,448 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 42938 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:12,702 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 44120 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:14,031 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 44431 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:15,291 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 45005 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:16,478 : INFO : EPOCH 1 - PROGRESS: at 95.33% examples, 45369 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:38:16,480 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:38:16,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:38:16,609 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:38:16,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:38:16,715 : INFO : EPOCH - 1 : training on 632490 raw words (485899 effective words) took 10.4s, 46523 effective words/s\n",
      "2018-08-01 13:38:17,973 : INFO : EPOCH 2 - PROGRESS: at 8.00% examples, 30640 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:19,323 : INFO : EPOCH 2 - PROGRESS: at 20.75% examples, 38354 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:20,618 : INFO : EPOCH 2 - PROGRESS: at 33.35% examples, 41398 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:21,917 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 42799 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:23,130 : INFO : EPOCH 2 - PROGRESS: at 58.87% examples, 44273 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:24,355 : INFO : EPOCH 2 - PROGRESS: at 71.41% examples, 45182 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:25,640 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 45528 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:26,769 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 46105 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:38:26,770 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:38:26,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:38:26,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:38:27,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:38:27,019 : INFO : EPOCH - 2 : training on 632490 raw words (485913 effective words) took 10.3s, 47198 effective words/s\n",
      "2018-08-01 13:38:28,303 : INFO : EPOCH 3 - PROGRESS: at 8.00% examples, 30391 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:29,519 : INFO : EPOCH 3 - PROGRESS: at 20.65% examples, 40278 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:30,744 : INFO : EPOCH 3 - PROGRESS: at 33.35% examples, 43541 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:32,010 : INFO : EPOCH 3 - PROGRESS: at 46.07% examples, 44785 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:33,267 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 45589 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:34,445 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 46592 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:35,733 : INFO : EPOCH 3 - PROGRESS: at 83.60% examples, 46702 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:36,861 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 47166 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:38:36,863 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:38:36,995 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:38:37,005 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:38:37,129 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:38:37,130 : INFO : EPOCH - 3 : training on 632490 raw words (485997 effective words) took 10.1s, 48163 effective words/s\n",
      "2018-08-01 13:38:38,392 : INFO : EPOCH 4 - PROGRESS: at 7.92% examples, 30491 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:39,701 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 38952 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:40,951 : INFO : EPOCH 4 - PROGRESS: at 33.35% examples, 42313 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:42,176 : INFO : EPOCH 4 - PROGRESS: at 45.97% examples, 44164 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:43,370 : INFO : EPOCH 4 - PROGRESS: at 58.87% examples, 45566 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:44,642 : INFO : EPOCH 4 - PROGRESS: at 71.41% examples, 45999 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:45,836 : INFO : EPOCH 4 - PROGRESS: at 83.56% examples, 46713 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:47,024 : INFO : EPOCH 4 - PROGRESS: at 96.12% examples, 47259 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:38:47,025 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:38:47,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:38:47,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:38:47,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:38:47,173 : INFO : EPOCH - 4 : training on 632490 raw words (486273 effective words) took 10.0s, 48462 effective words/s\n",
      "2018-08-01 13:38:48,387 : INFO : EPOCH 5 - PROGRESS: at 8.00% examples, 31769 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:49,695 : INFO : EPOCH 5 - PROGRESS: at 20.75% examples, 39672 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:50,887 : INFO : EPOCH 5 - PROGRESS: at 33.35% examples, 43469 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:52,112 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 45097 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:53,355 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 45943 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:54,628 : INFO : EPOCH 5 - PROGRESS: at 71.41% examples, 46334 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:55,897 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 46594 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:38:56,960 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 47366 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:38:56,961 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:38:57,164 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:38:57,237 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:38:57,268 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:38:57,269 : INFO : EPOCH - 5 : training on 632490 raw words (485882 effective words) took 10.1s, 48169 effective words/s\n",
      "2018-08-01 13:38:57,270 : INFO : training on a 3162450 raw words (2429964 effective words) took 51.0s, 47639 effective words/s\n",
      "2018-08-01 13:38:57,273 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:38:58,623 : INFO : EPOCH 1 - PROGRESS: at 7.92% examples, 28594 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:38:59,889 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 38264 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:01,098 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 42219 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:02,292 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 44358 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:03,520 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 45460 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:04,741 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 46231 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:05,943 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 46872 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:07,054 : INFO : EPOCH 1 - PROGRESS: at 95.33% examples, 47413 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:39:07,055 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:39:07,172 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:39:07,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:39:07,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:39:07,313 : INFO : EPOCH - 1 : training on 632490 raw words (485847 effective words) took 10.0s, 48465 effective words/s\n",
      "2018-08-01 13:39:08,556 : INFO : EPOCH 2 - PROGRESS: at 8.06% examples, 31139 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:09,759 : INFO : EPOCH 2 - PROGRESS: at 20.61% examples, 41092 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:10,937 : INFO : EPOCH 2 - PROGRESS: at 33.35% examples, 44733 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:12,211 : INFO : EPOCH 2 - PROGRESS: at 46.07% examples, 45583 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:13,456 : INFO : EPOCH 2 - PROGRESS: at 58.87% examples, 46331 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:14,670 : INFO : EPOCH 2 - PROGRESS: at 71.41% examples, 46999 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:39:15,938 : INFO : EPOCH 2 - PROGRESS: at 83.60% examples, 47154 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:16,952 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 48145 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:39:16,956 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:39:17,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:39:17,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:39:17,222 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:39:17,223 : INFO : EPOCH - 2 : training on 632490 raw words (486060 effective words) took 9.9s, 49133 effective words/s\n",
      "2018-08-01 13:39:18,436 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 31761 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:19,719 : INFO : EPOCH 3 - PROGRESS: at 20.65% examples, 40123 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:20,892 : INFO : EPOCH 3 - PROGRESS: at 33.35% examples, 44077 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:22,171 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 45066 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:23,413 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 45920 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:24,666 : INFO : EPOCH 3 - PROGRESS: at 71.44% examples, 46385 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:25,946 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 46583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:27,023 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 47317 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:39:27,025 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:39:27,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:39:27,211 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:39:27,265 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:39:27,266 : INFO : EPOCH - 3 : training on 632490 raw words (486096 effective words) took 10.0s, 48445 effective words/s\n",
      "2018-08-01 13:39:28,803 : INFO : EPOCH 4 - PROGRESS: at 8.06% examples, 25064 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:29,993 : INFO : EPOCH 4 - PROGRESS: at 20.61% examples, 36711 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:31,233 : INFO : EPOCH 4 - PROGRESS: at 33.35% examples, 40752 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:32,471 : INFO : EPOCH 4 - PROGRESS: at 46.07% examples, 42844 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:33,694 : INFO : EPOCH 4 - PROGRESS: at 58.87% examples, 44231 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:34,914 : INFO : EPOCH 4 - PROGRESS: at 71.41% examples, 45167 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:36,158 : INFO : EPOCH 4 - PROGRESS: at 83.56% examples, 45716 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:37,237 : INFO : EPOCH 4 - PROGRESS: at 95.33% examples, 46513 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:39:37,239 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:39:37,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:39:37,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:39:37,451 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:39:37,452 : INFO : EPOCH - 4 : training on 632490 raw words (486005 effective words) took 10.2s, 47770 effective words/s\n",
      "2018-08-01 13:39:38,711 : INFO : EPOCH 5 - PROGRESS: at 8.06% examples, 30526 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:39,960 : INFO : EPOCH 5 - PROGRESS: at 20.61% examples, 39884 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:41,243 : INFO : EPOCH 5 - PROGRESS: at 33.46% examples, 42605 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:42,488 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 44219 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:43,698 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 45498 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:44,886 : INFO : EPOCH 5 - PROGRESS: at 71.44% examples, 46433 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:46,077 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 47111 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:47,199 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 47577 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:39:47,200 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:39:47,344 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:39:47,359 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:39:47,403 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:39:47,404 : INFO : EPOCH - 5 : training on 632490 raw words (486109 effective words) took 9.9s, 48888 effective words/s\n",
      "2018-08-01 13:39:47,406 : INFO : training on a 3162450 raw words (2430117 effective words) took 50.1s, 48478 effective words/s\n",
      "2018-08-01 13:39:47,408 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:39:48,640 : INFO : EPOCH 1 - PROGRESS: at 8.00% examples, 31524 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:50,076 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 37637 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:51,496 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 39612 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:52,755 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 41717 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:39:54,057 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 42788 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:55,433 : INFO : EPOCH 1 - PROGRESS: at 71.44% examples, 43054 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:56,741 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 43574 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:39:57,829 : INFO : EPOCH 1 - PROGRESS: at 95.33% examples, 44523 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:39:57,830 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:39:57,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:39:57,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:39:58,034 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:39:58,035 : INFO : EPOCH - 1 : training on 632490 raw words (486152 effective words) took 10.6s, 45807 effective words/s\n",
      "2018-08-01 13:39:59,283 : INFO : EPOCH 2 - PROGRESS: at 8.06% examples, 30804 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:00,551 : INFO : EPOCH 2 - PROGRESS: at 20.75% examples, 39756 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:01,798 : INFO : EPOCH 2 - PROGRESS: at 33.41% examples, 42879 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:03,082 : INFO : EPOCH 2 - PROGRESS: at 46.07% examples, 44077 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:04,309 : INFO : EPOCH 2 - PROGRESS: at 58.87% examples, 45251 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:05,565 : INFO : EPOCH 2 - PROGRESS: at 71.41% examples, 45832 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:06,834 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 46169 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:07,840 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 47274 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:40:07,841 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:40:08,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:40:08,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:40:08,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:40:08,082 : INFO : EPOCH - 2 : training on 632490 raw words (485890 effective words) took 10.0s, 48401 effective words/s\n",
      "2018-08-01 13:40:09,287 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 32014 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:10,535 : INFO : EPOCH 3 - PROGRESS: at 20.61% examples, 40793 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:11,775 : INFO : EPOCH 3 - PROGRESS: at 33.46% examples, 43745 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:40:12,979 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 45472 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:14,230 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 46207 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:15,462 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 46791 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:16,694 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 47199 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:17,858 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 47436 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:40:17,859 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:40:17,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:40:18,007 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:40:18,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:40:18,026 : INFO : EPOCH - 3 : training on 632490 raw words (485972 effective words) took 9.9s, 48923 effective words/s\n",
      "2018-08-01 13:40:19,255 : INFO : EPOCH 4 - PROGRESS: at 8.00% examples, 31413 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:20,495 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 40558 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:21,738 : INFO : EPOCH 4 - PROGRESS: at 33.35% examples, 43556 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:22,922 : INFO : EPOCH 4 - PROGRESS: at 45.97% examples, 45514 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:24,131 : INFO : EPOCH 4 - PROGRESS: at 58.87% examples, 46537 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:25,410 : INFO : EPOCH 4 - PROGRESS: at 71.41% examples, 46775 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:26,691 : INFO : EPOCH 4 - PROGRESS: at 83.56% examples, 46922 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:27,679 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:40:27,860 : INFO : EPOCH 4 - PROGRESS: at 96.95% examples, 47929 words/s, in_qsize 2, out_qsize 1\n",
      "2018-08-01 13:40:27,862 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:40:27,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:40:27,954 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:40:27,955 : INFO : EPOCH - 4 : training on 632490 raw words (486263 effective words) took 9.9s, 49016 effective words/s\n",
      "2018-08-01 13:40:29,210 : INFO : EPOCH 5 - PROGRESS: at 8.06% examples, 30680 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:30,367 : INFO : EPOCH 5 - PROGRESS: at 20.65% examples, 41491 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:31,549 : INFO : EPOCH 5 - PROGRESS: at 33.35% examples, 44968 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:32,813 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 45840 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:34,006 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 46971 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:35,220 : INFO : EPOCH 5 - PROGRESS: at 71.41% examples, 47558 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:36,424 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 48004 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:37,624 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 47979 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:40:37,625 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:40:37,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:40:37,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:40:37,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:40:37,833 : INFO : EPOCH - 5 : training on 632490 raw words (486240 effective words) took 9.9s, 49267 effective words/s\n",
      "2018-08-01 13:40:37,834 : INFO : training on a 3162450 raw words (2430517 effective words) took 50.4s, 48203 effective words/s\n",
      "2018-08-01 13:40:37,835 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:40:39,013 : INFO : EPOCH 1 - PROGRESS: at 8.00% examples, 32761 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:40,301 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 40550 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:41,566 : INFO : EPOCH 1 - PROGRESS: at 33.41% examples, 43280 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:42,830 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 44603 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:44,038 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 45828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:45,285 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 46363 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:46,452 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 47181 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:47,432 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:40:47,647 : INFO : EPOCH 1 - PROGRESS: at 96.86% examples, 48057 words/s, in_qsize 2, out_qsize 1\n",
      "2018-08-01 13:40:47,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:40:47,667 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:40:47,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:40:47,727 : INFO : EPOCH - 1 : training on 632490 raw words (486151 effective words) took 9.9s, 49195 effective words/s\n",
      "2018-08-01 13:40:48,969 : INFO : EPOCH 2 - PROGRESS: at 8.06% examples, 31125 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:50,239 : INFO : EPOCH 2 - PROGRESS: at 20.65% examples, 39950 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:51,471 : INFO : EPOCH 2 - PROGRESS: at 33.35% examples, 43238 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:52,671 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 45094 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:40:53,865 : INFO : EPOCH 2 - PROGRESS: at 58.87% examples, 46327 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:55,113 : INFO : EPOCH 2 - PROGRESS: at 71.41% examples, 46785 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:56,394 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 46931 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:40:57,451 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 47715 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:40:57,452 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:40:57,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:40:57,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:40:57,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:40:57,677 : INFO : EPOCH - 2 : training on 632490 raw words (486121 effective words) took 9.9s, 48926 effective words/s\n",
      "2018-08-01 13:40:58,907 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 31331 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:00,131 : INFO : EPOCH 3 - PROGRESS: at 20.61% examples, 40778 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:01,352 : INFO : EPOCH 3 - PROGRESS: at 33.46% examples, 43969 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:02,565 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 45572 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:03,753 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 46755 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:04,970 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 47366 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:06,227 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 47568 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:07,234 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 48554 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:41:07,236 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:41:07,421 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:41:07,465 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:41:07,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:41:07,483 : INFO : EPOCH - 3 : training on 632490 raw words (486466 effective words) took 9.8s, 49655 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:41:08,743 : INFO : EPOCH 4 - PROGRESS: at 8.00% examples, 30799 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:10,014 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 39781 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:11,256 : INFO : EPOCH 4 - PROGRESS: at 33.41% examples, 42944 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:12,505 : INFO : EPOCH 4 - PROGRESS: at 45.97% examples, 44448 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:13,768 : INFO : EPOCH 4 - PROGRESS: at 58.87% examples, 45266 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:14,975 : INFO : EPOCH 4 - PROGRESS: at 71.41% examples, 46128 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:16,153 : INFO : EPOCH 4 - PROGRESS: at 83.56% examples, 46910 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:17,185 : INFO : EPOCH 4 - PROGRESS: at 95.33% examples, 47826 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:41:17,186 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:41:17,359 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:41:17,368 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:41:17,442 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:41:17,443 : INFO : EPOCH - 4 : training on 632490 raw words (486217 effective words) took 9.9s, 48883 effective words/s\n",
      "2018-08-01 13:41:18,684 : INFO : EPOCH 5 - PROGRESS: at 8.06% examples, 30926 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:19,972 : INFO : EPOCH 5 - PROGRESS: at 20.61% examples, 39524 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:21,199 : INFO : EPOCH 5 - PROGRESS: at 33.35% examples, 42977 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:22,441 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 44546 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:23,595 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 46148 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:24,843 : INFO : EPOCH 5 - PROGRESS: at 71.38% examples, 46633 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:26,072 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 47072 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:27,106 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 47967 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:41:27,107 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:41:27,272 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:41:27,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:41:27,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:41:27,317 : INFO : EPOCH - 5 : training on 632490 raw words (485861 effective words) took 9.9s, 49240 effective words/s\n",
      "2018-08-01 13:41:27,318 : INFO : training on a 3162450 raw words (2430816 effective words) took 49.5s, 49127 effective words/s\n",
      "2018-08-01 13:41:27,319 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:41:28,545 : INFO : EPOCH 1 - PROGRESS: at 8.00% examples, 31635 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:29,770 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 41025 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:30,969 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 44403 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:32,206 : INFO : EPOCH 1 - PROGRESS: at 46.07% examples, 45702 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:33,449 : INFO : EPOCH 1 - PROGRESS: at 58.84% examples, 46421 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:34,614 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 47401 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:35,827 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 47826 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:36,938 : INFO : EPOCH 1 - PROGRESS: at 95.33% examples, 48245 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:41:36,940 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:41:37,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:41:37,115 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:41:37,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:41:37,147 : INFO : EPOCH - 1 : training on 632490 raw words (486130 effective words) took 9.8s, 49544 effective words/s\n",
      "2018-08-01 13:41:38,364 : INFO : EPOCH 2 - PROGRESS: at 8.00% examples, 31792 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:39,612 : INFO : EPOCH 2 - PROGRESS: at 20.61% examples, 40644 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:40,932 : INFO : EPOCH 2 - PROGRESS: at 33.35% examples, 42709 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:42,158 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 44442 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:43,420 : INFO : EPOCH 2 - PROGRESS: at 58.94% examples, 45301 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:44,633 : INFO : EPOCH 2 - PROGRESS: at 71.44% examples, 46121 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:45,797 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 46996 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:46,830 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 47902 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:41:46,831 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:41:47,064 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:41:47,075 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:41:47,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:41:47,083 : INFO : EPOCH - 2 : training on 632490 raw words (486169 effective words) took 9.9s, 48981 effective words/s\n",
      "2018-08-01 13:41:48,295 : INFO : EPOCH 3 - PROGRESS: at 8.00% examples, 31963 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:49,716 : INFO : EPOCH 3 - PROGRESS: at 20.61% examples, 38082 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:50,995 : INFO : EPOCH 3 - PROGRESS: at 33.35% examples, 41364 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:52,379 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 42121 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:53,726 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 42804 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:55,113 : INFO : EPOCH 3 - PROGRESS: at 71.44% examples, 43020 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:41:56,342 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 43912 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:41:57,383 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 45023 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:41:57,384 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:41:57,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:41:57,626 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:41:57,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:41:57,681 : INFO : EPOCH - 3 : training on 632490 raw words (486159 effective words) took 10.6s, 45921 effective words/s\n",
      "2018-08-01 13:41:58,926 : INFO : EPOCH 4 - PROGRESS: at 8.06% examples, 30995 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:00,165 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 40319 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:01,409 : INFO : EPOCH 4 - PROGRESS: at 33.46% examples, 43372 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:02,697 : INFO : EPOCH 4 - PROGRESS: at 45.97% examples, 44438 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:03,953 : INFO : EPOCH 4 - PROGRESS: at 58.87% examples, 45301 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:05,141 : INFO : EPOCH 4 - PROGRESS: at 71.41% examples, 46291 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:06,393 : INFO : EPOCH 4 - PROGRESS: at 83.56% examples, 46661 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:07,422 : INFO : EPOCH 4 - PROGRESS: at 95.33% examples, 47609 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:42:07,424 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:42:07,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:42:07,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:42:07,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:42:07,672 : INFO : EPOCH - 4 : training on 632490 raw words (486062 effective words) took 10.0s, 48705 effective words/s\n",
      "2018-08-01 13:42:08,917 : INFO : EPOCH 5 - PROGRESS: at 8.00% examples, 30947 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:10,158 : INFO : EPOCH 5 - PROGRESS: at 20.61% examples, 40277 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:11,389 : INFO : EPOCH 5 - PROGRESS: at 33.35% examples, 43487 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:12,554 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 45645 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:13,786 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 46486 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:15,027 : INFO : EPOCH 5 - PROGRESS: at 71.41% examples, 46951 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:16,278 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 47226 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:17,357 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 47876 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:42:17,358 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:42:17,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:42:17,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:42:17,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:42:17,636 : INFO : EPOCH - 5 : training on 632490 raw words (486062 effective words) took 10.0s, 48825 effective words/s\n",
      "2018-08-01 13:42:17,637 : INFO : training on a 3162450 raw words (2430582 effective words) took 50.3s, 48307 effective words/s\n",
      "2018-08-01 13:42:17,638 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:42:18,849 : INFO : EPOCH 1 - PROGRESS: at 7.92% examples, 31855 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:20,074 : INFO : EPOCH 1 - PROGRESS: at 20.65% examples, 41088 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:21,289 : INFO : EPOCH 1 - PROGRESS: at 33.46% examples, 44252 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:22,513 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 45700 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:23,738 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 46583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:25,007 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 46872 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:26,237 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 47276 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:27,265 : INFO : EPOCH 1 - PROGRESS: at 95.33% examples, 48174 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:42:27,267 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:42:27,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:42:27,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:42:27,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:42:27,531 : INFO : EPOCH - 1 : training on 632490 raw words (486147 effective words) took 9.9s, 49185 effective words/s\n",
      "2018-08-01 13:42:28,749 : INFO : EPOCH 2 - PROGRESS: at 7.92% examples, 31666 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:29,977 : INFO : EPOCH 2 - PROGRESS: at 20.61% examples, 40948 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:31,203 : INFO : EPOCH 2 - PROGRESS: at 33.35% examples, 44007 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:32,411 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 45661 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:33,656 : INFO : EPOCH 2 - PROGRESS: at 58.87% examples, 46397 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:34,880 : INFO : EPOCH 2 - PROGRESS: at 71.41% examples, 46998 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:36,025 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 47846 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:37,158 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 48163 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:42:37,159 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:42:37,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:42:37,283 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:42:37,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:42:37,394 : INFO : EPOCH - 2 : training on 632490 raw words (485952 effective words) took 9.9s, 49324 effective words/s\n",
      "2018-08-01 13:42:38,617 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 31505 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:39,895 : INFO : EPOCH 3 - PROGRESS: at 20.61% examples, 39994 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:41,153 : INFO : EPOCH 3 - PROGRESS: at 33.46% examples, 42970 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:42,358 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 44857 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:43,509 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 46457 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:44,715 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 47156 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:45,942 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 47534 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:47,063 : INFO : EPOCH 3 - PROGRESS: at 95.33% examples, 47940 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:42:47,065 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:42:47,083 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:42:47,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:42:47,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:42:47,292 : INFO : EPOCH - 3 : training on 632490 raw words (486020 effective words) took 9.9s, 49139 effective words/s\n",
      "2018-08-01 13:42:48,543 : INFO : EPOCH 4 - PROGRESS: at 8.00% examples, 30834 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:49,780 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 40281 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:50,913 : INFO : EPOCH 4 - PROGRESS: at 33.35% examples, 44645 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:52,172 : INFO : EPOCH 4 - PROGRESS: at 46.07% examples, 45699 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:53,395 : INFO : EPOCH 4 - PROGRESS: at 58.84% examples, 46575 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:42:54,623 : INFO : EPOCH 4 - PROGRESS: at 71.44% examples, 47098 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:55,923 : INFO : EPOCH 4 - PROGRESS: at 83.60% examples, 47091 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:57,093 : INFO : EPOCH 4 - PROGRESS: at 95.33% examples, 47337 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:42:57,095 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:42:57,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:42:57,152 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:42:57,153 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:42:57,154 : INFO : EPOCH - 4 : training on 632490 raw words (486444 effective words) took 9.9s, 49370 effective words/s\n",
      "2018-08-01 13:42:58,379 : INFO : EPOCH 5 - PROGRESS: at 8.00% examples, 31639 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:42:59,600 : INFO : EPOCH 5 - PROGRESS: at 20.61% examples, 41041 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:00,838 : INFO : EPOCH 5 - PROGRESS: at 33.41% examples, 43928 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:02,048 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 45612 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:03,324 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 46121 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:43:04,518 : INFO : EPOCH 5 - PROGRESS: at 71.41% examples, 46960 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:05,756 : INFO : EPOCH 5 - PROGRESS: at 83.56% examples, 47287 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:06,794 : INFO : EPOCH 5 - PROGRESS: at 95.33% examples, 48149 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:43:06,795 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:43:06,975 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:43:07,035 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:43:07,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:43:07,076 : INFO : EPOCH - 5 : training on 632490 raw words (486246 effective words) took 9.9s, 49081 effective words/s\n",
      "2018-08-01 13:43:07,077 : INFO : training on a 3162450 raw words (2430809 effective words) took 49.4s, 49170 effective words/s\n",
      "2018-08-01 13:43:07,082 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:43:08,273 : INFO : EPOCH 1 - PROGRESS: at 7.92% examples, 32361 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:09,503 : INFO : EPOCH 1 - PROGRESS: at 20.75% examples, 41358 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:10,866 : INFO : EPOCH 1 - PROGRESS: at 33.41% examples, 42660 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:12,067 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 44686 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:13,273 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 45904 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:14,465 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 46787 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:15,701 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 47167 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:16,892 : INFO : EPOCH 1 - PROGRESS: at 95.33% examples, 47278 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:43:16,893 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:43:16,920 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:43:16,934 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:43:16,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:43:16,944 : INFO : EPOCH - 1 : training on 632490 raw words (486097 effective words) took 9.9s, 49343 effective words/s\n",
      "2018-08-01 13:43:18,273 : INFO : EPOCH 2 - PROGRESS: at 8.00% examples, 29040 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:19,481 : INFO : EPOCH 2 - PROGRESS: at 20.75% examples, 39533 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:20,727 : INFO : EPOCH 2 - PROGRESS: at 33.46% examples, 42770 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:21,955 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 44532 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:23,205 : INFO : EPOCH 2 - PROGRESS: at 58.84% examples, 45440 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:24,418 : INFO : EPOCH 2 - PROGRESS: at 71.41% examples, 46254 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:25,653 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 46706 words/s, in_qsize 7, out_qsize 1\n",
      "2018-08-01 13:43:26,687 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 47643 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:43:26,689 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:43:26,841 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:43:26,873 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:43:26,878 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:43:26,879 : INFO : EPOCH - 2 : training on 632490 raw words (486442 effective words) took 9.9s, 49022 effective words/s\n",
      "2018-08-01 13:43:28,112 : INFO : EPOCH 3 - PROGRESS: at 8.00% examples, 31497 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:29,326 : INFO : EPOCH 3 - PROGRESS: at 20.65% examples, 41105 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:30,571 : INFO : EPOCH 3 - PROGRESS: at 33.41% examples, 43840 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:31,825 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 45096 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:33,191 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 45060 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:34,860 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 43292 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:35,956 : INFO : EPOCH 3 - PROGRESS: at 79.03% examples, 42248 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:37,491 : INFO : EPOCH 3 - PROGRESS: at 89.59% examples, 41162 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:38,030 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:43:38,201 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:43:38,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:43:38,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:43:38,403 : INFO : EPOCH - 3 : training on 632490 raw words (485650 effective words) took 11.5s, 42212 effective words/s\n",
      "2018-08-01 13:43:39,597 : INFO : EPOCH 4 - PROGRESS: at 8.00% examples, 32360 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:40,976 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 38916 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:41,990 : INFO : EPOCH 4 - PROGRESS: at 26.74% examples, 36444 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:43,333 : INFO : EPOCH 4 - PROGRESS: at 39.74% examples, 38970 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:44,674 : INFO : EPOCH 4 - PROGRESS: at 52.26% examples, 40396 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:46,000 : INFO : EPOCH 4 - PROGRESS: at 65.32% examples, 41414 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:47,252 : INFO : EPOCH 4 - PROGRESS: at 77.53% examples, 42455 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:48,407 : INFO : EPOCH 4 - PROGRESS: at 89.59% examples, 43652 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:48,743 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:43:48,917 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:43:48,962 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:43:48,975 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:43:48,975 : INFO : EPOCH - 4 : training on 632490 raw words (485614 effective words) took 10.6s, 45992 effective words/s\n",
      "2018-08-01 13:43:50,196 : INFO : EPOCH 5 - PROGRESS: at 8.06% examples, 31550 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:51,421 : INFO : EPOCH 5 - PROGRESS: at 20.65% examples, 40970 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:52,589 : INFO : EPOCH 5 - PROGRESS: at 33.35% examples, 44735 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:54,048 : INFO : EPOCH 5 - PROGRESS: at 46.00% examples, 43967 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:55,924 : INFO : EPOCH 5 - PROGRESS: at 58.94% examples, 40911 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:57,034 : INFO : EPOCH 5 - PROGRESS: at 65.34% examples, 39050 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:58,276 : INFO : EPOCH 5 - PROGRESS: at 77.53% examples, 40408 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:43:59,392 : INFO : EPOCH 5 - PROGRESS: at 89.59% examples, 41937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:43:59,792 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:43:59,932 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:43:59,965 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:43:59,999 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:43:59,999 : INFO : EPOCH - 5 : training on 632490 raw words (486168 effective words) took 11.0s, 44130 effective words/s\n",
      "2018-08-01 13:44:00,000 : INFO : training on a 3162450 raw words (2429971 effective words) took 52.9s, 45922 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 13:44:00,001 : INFO : training model with 4 workers on 2462 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-08-01 13:44:01,095 : INFO : EPOCH 1 - PROGRESS: at 8.00% examples, 35353 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:02,220 : INFO : EPOCH 1 - PROGRESS: at 20.61% examples, 45179 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:03,383 : INFO : EPOCH 1 - PROGRESS: at 33.27% examples, 47816 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:04,511 : INFO : EPOCH 1 - PROGRESS: at 45.97% examples, 49430 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:05,686 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 50021 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:06,861 : INFO : EPOCH 1 - PROGRESS: at 71.41% examples, 50388 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:07,993 : INFO : EPOCH 1 - PROGRESS: at 83.60% examples, 50875 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:08,957 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:44:09,080 : INFO : EPOCH 1 - PROGRESS: at 96.95% examples, 51926 words/s, in_qsize 2, out_qsize 1\n",
      "2018-08-01 13:44:09,082 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:44:09,108 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:44:09,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:44:09,122 : INFO : EPOCH - 1 : training on 632490 raw words (486051 effective words) took 9.1s, 53360 effective words/s\n",
      "2018-08-01 13:44:10,262 : INFO : EPOCH 2 - PROGRESS: at 8.06% examples, 33825 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:11,384 : INFO : EPOCH 2 - PROGRESS: at 20.61% examples, 44289 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:12,500 : INFO : EPOCH 2 - PROGRESS: at 33.35% examples, 47817 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:13,616 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 49548 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:14,767 : INFO : EPOCH 2 - PROGRESS: at 58.87% examples, 50301 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:15,883 : INFO : EPOCH 2 - PROGRESS: at 71.41% examples, 51014 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:17,036 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 51309 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:18,089 : INFO : EPOCH 2 - PROGRESS: at 95.33% examples, 51664 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:44:18,090 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:44:18,140 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:44:18,148 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:44:18,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:44:18,225 : INFO : EPOCH - 2 : training on 632490 raw words (485557 effective words) took 9.1s, 53399 effective words/s\n",
      "2018-08-01 13:44:19,314 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 35342 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:20,461 : INFO : EPOCH 3 - PROGRESS: at 20.65% examples, 44755 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:21,597 : INFO : EPOCH 3 - PROGRESS: at 33.35% examples, 47878 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:22,691 : INFO : EPOCH 3 - PROGRESS: at 45.97% examples, 49853 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:23,849 : INFO : EPOCH 3 - PROGRESS: at 58.84% examples, 50512 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:24,990 : INFO : EPOCH 3 - PROGRESS: at 71.41% examples, 51042 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:26,174 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 51131 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:27,261 : INFO : EPOCH 3 - PROGRESS: at 92.87% examples, 50032 words/s, in_qsize 5, out_qsize 0\n",
      "2018-08-01 13:44:27,854 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:44:28,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:44:28,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:44:28,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:44:28,164 : INFO : EPOCH - 3 : training on 632490 raw words (486181 effective words) took 9.9s, 48955 effective words/s\n",
      "2018-08-01 13:44:29,690 : INFO : EPOCH 4 - PROGRESS: at 8.00% examples, 25459 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:32,376 : INFO : EPOCH 4 - PROGRESS: at 20.65% examples, 23798 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:33,458 : INFO : EPOCH 4 - PROGRESS: at 26.74% examples, 24708 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:34,470 : INFO : EPOCH 4 - PROGRESS: at 35.00% examples, 26856 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:36,269 : INFO : EPOCH 4 - PROGRESS: at 45.97% examples, 27501 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:37,577 : INFO : EPOCH 4 - PROGRESS: at 54.13% examples, 27758 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:38,685 : INFO : EPOCH 4 - PROGRESS: at 60.42% examples, 27748 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:39,812 : INFO : EPOCH 4 - PROGRESS: at 66.70% examples, 27697 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:40,859 : INFO : EPOCH 4 - PROGRESS: at 72.96% examples, 27818 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:41,885 : INFO : EPOCH 4 - PROGRESS: at 82.13% examples, 29072 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:42,939 : INFO : EPOCH 4 - PROGRESS: at 86.45% examples, 28545 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:44,156 : INFO : EPOCH 4 - PROGRESS: at 95.33% examples, 29010 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:44:44,158 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:44:44,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:44:44,260 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:44:44,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:44:44,289 : INFO : EPOCH - 4 : training on 632490 raw words (486189 effective words) took 16.1s, 30186 effective words/s\n",
      "2018-08-01 13:44:45,712 : INFO : EPOCH 5 - PROGRESS: at 8.06% examples, 27028 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:46,989 : INFO : EPOCH 5 - PROGRESS: at 20.65% examples, 37050 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:48,213 : INFO : EPOCH 5 - PROGRESS: at 33.35% examples, 41177 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:49,472 : INFO : EPOCH 5 - PROGRESS: at 45.97% examples, 42966 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:50,817 : INFO : EPOCH 5 - PROGRESS: at 58.87% examples, 43516 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:52,147 : INFO : EPOCH 5 - PROGRESS: at 71.41% examples, 43947 words/s, in_qsize 7, out_qsize 0\n",
      "2018-08-01 13:44:53,303 : INFO : EPOCH 5 - PROGRESS: at 83.60% examples, 45075 words/s, in_qsize 8, out_qsize 0\n",
      "2018-08-01 13:44:54,380 : INFO : EPOCH 5 - PROGRESS: at 96.12% examples, 46313 words/s, in_qsize 3, out_qsize 1\n",
      "2018-08-01 13:44:54,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-08-01 13:44:54,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-08-01 13:44:54,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-08-01 13:44:54,451 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-08-01 13:44:54,451 : INFO : EPOCH - 5 : training on 632490 raw words (486010 effective words) took 10.2s, 47866 effective words/s\n",
      "2018-08-01 13:44:54,452 : INFO : training on a 3162450 raw words (2429988 effective words) took 54.4s, 44629 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 519.625382900238\n"
     ]
    }
   ],
   "source": [
    "# 벡터 문서 학습\n",
    "start = time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 14:00:53,424 : INFO : saving Doc2Vec object under model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model, separately None\n",
      "2018-08-01 14:00:53,636 : INFO : saved model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model\n"
     ]
    }
   ],
   "source": [
    "# doc2vec 모델 저장\n",
    "model_name = 'model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model'\n",
    "doc_vectorizer.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 14:00:57,792 : INFO : loading Doc2Vec object from model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model\n",
      "2018-08-01 14:00:57,922 : INFO : loading vocabulary recursively from model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model.vocabulary.* with mmap=None\n",
      "2018-08-01 14:00:57,927 : INFO : loading trainables recursively from model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model.trainables.* with mmap=None\n",
      "2018-08-01 14:00:57,929 : INFO : loading wv recursively from model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model.wv.* with mmap=None\n",
      "2018-08-01 14:00:57,930 : INFO : loading docvecs recursively from model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model.docvecs.* with mmap=None\n",
      "2018-08-01 14:00:57,931 : INFO : loaded model/Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t4).model\n"
     ]
    }
   ],
   "source": [
    "# doc2vec 모델 로드\n",
    "doc_vectorizer = doc2vec.Doc2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('좋다/Adjective', 0.38780662417411804), ('속/Noun', 0.3300017714500427), ('땡기다/Verb', 0.3296898901462555), ('보습/Noun', 0.3006742596626282), ('도/Josa', 0.30008891224861145), ('촉촉/Noun', 0.2879345417022705), ('은/Josa', 0.2849486470222473), ('가볍다/Adjective', 0.2838784158229828), ('미스트/Noun', 0.27317193150520325), ('향/Noun', 0.26660752296447754)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# doc2vec 모델 탐색\n",
    "print(doc_vectorizer.wv.most_similar('촉촉하다/Adjective'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('건성/Noun', 0.30199867486953735), ('푸석/Adverb', 0.29866117238998413), ('땡기다/Verb', 0.291866272687912), ('세안/Noun', 0.2816868722438812), ('당기다/Verb', 0.2759491205215454), ('바르다/Verb', 0.26370900869369507), ('입술/Noun', 0.2558313310146332), ('지성/Noun', 0.2551003694534302), ('부족하다/Adjective', 0.2455301135778427), ('피부/Noun', 0.24286693334579468)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(doc_vectorizer.wv.most_similar('건조하다/Adjective'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 모델 평가 : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y_train = [doc.tags for doc in tagged_train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]\n",
    "y_test = [doc.tags for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15916, 15916, 5306, 5306)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1.059430s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "clf.fit(X_train, y_train)\n",
    "end = time()\n",
    "print('Time: {:f}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 0.835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"테스트 정확도: {:.3f}\".format(accuracy_score(y_pred, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
